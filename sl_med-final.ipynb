{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Using  Breastmnist data set from medmnist.**\n"
      ],
      "metadata": {
        "id": "ds135v5S21CV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jgoqkLKw7Ay",
        "outputId": "0ad156d2-2d6e-4c69-8393-95ae9d516cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (9.4.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.16.0+cu121)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=78e82d56cbdcabcaa33a69c3afd5cf80f6f8625b3023a69e0a6e6d46d0922c81\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import medmnist\n",
        "from medmnist import INFO\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Choose the BreastMNIST dataset\n",
        "data_flag = 'breastmnist'\n",
        "info = INFO[data_flag]\n",
        "n_channels = info['n_channels']\n",
        "n_classes = 2  # Binary classification for BreastMNIST\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Load the dataset with transforms\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "train_data = DataClass(split='train', download=True, transform=transform)\n",
        "test_data = DataClass(split='test', download=True, transform=transform)\n",
        "\n",
        "# Determine the size of each split\n",
        "split_size = len(train_data) // 6\n",
        "\n",
        "# Create indices for splitting the data\n",
        "indices = torch.randperm(len(train_data)).tolist()\n",
        "\n",
        "# Split data into 6 parts\n",
        "client_datasets = [Subset(train_data, indices[i*split_size : (i+1)*split_size]) for i in range(6)]\n",
        "\n",
        "# Create data loaders for each client\n",
        "batch_size = 32  # You can adjust the batch size\n",
        "client_loaders = [DataLoader(dataset, batch_size=batch_size, shuffle=True) for dataset in client_datasets]\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define Client Model\n",
        "class ClientModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClientModel, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(n_channels, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(7 * 7 * 32, 128)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Define Server Model\n",
        "class ServerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ServerModel, self).__init__()\n",
        "        # 768 features from the concatenated client outputs\n",
        "        self.fc1 = nn.Linear(768, 128)  # Intermediate layer\n",
        "        self.fc2 = nn.Linear(128, n_classes)  # Final layer for classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return torch.log_softmax(self.fc2(x), dim=1)\n",
        "\n",
        "\n",
        "# Initialize client and server models\n",
        "clients = [ClientModel().to(device) for _ in range(6)]\n",
        "server = ServerModel().to(device)\n",
        "\n",
        "# Define optimizers\n",
        "client_optimizers = [optim.SGD(client.parameters(), lr=0.01) for client in clients]\n",
        "server_optimizer = optim.SGD(server.parameters(), lr=0.01)\n",
        "\n",
        "# Training function\n",
        "def train(epoch):\n",
        "    server.train()\n",
        "    for client, optimizer, loader in zip(clients, client_optimizers, client_loaders):\n",
        "        client.train()\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            target = target.squeeze()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            client_outputs = [client(data) for client in clients]\n",
        "            aggregated_output = torch.cat(client_outputs, dim=1)\n",
        "            server_output = server(aggregated_output)\n",
        "            loss = nn.functional.nll_loss(server_output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}: Loss: {loss.item()}\")\n",
        "\n",
        "# Testing function\n",
        "def test():\n",
        "    server.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Ensure target is 1D: target might be [batch_size, 1], so we squeeze it\n",
        "            target = target.squeeze()\n",
        "\n",
        "            # Concatenate client outputs\n",
        "            client_outputs = [client(data) for client in clients]\n",
        "            aggregated_output = torch.cat(client_outputs, dim=1)\n",
        "            server_output = server(aggregated_output)\n",
        "\n",
        "            # Calculate loss\n",
        "            test_loss += nn.functional.nll_loss(server_output, target, reduction='sum').item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred = server_output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
        "\n",
        "\n",
        "# Run training and testing\n",
        "for epoch in range(1, 100):  # Adjust number of epochs as needed\n",
        "    train(epoch)\n",
        "test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "697s95GmyplP",
        "outputId": "daab1423-147e-48cb-beb9-f9615f1cd73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/records/10519652/files/breastmnist.npz?download=1 to /root/.medmnist/breastmnist.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 559580/559580 [00:00<00:00, 943217.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Epoch 1: Loss: 0.6877306699752808\n",
            "Epoch 2: Loss: 0.6857907772064209\n",
            "Epoch 3: Loss: 0.6814852356910706\n",
            "Epoch 4: Loss: 0.6797196865081787\n",
            "Epoch 5: Loss: 0.6734932065010071\n",
            "Epoch 6: Loss: 0.685573935508728\n",
            "Epoch 7: Loss: 0.6772541403770447\n",
            "Epoch 8: Loss: 0.6875381469726562\n",
            "Epoch 9: Loss: 0.6707359552383423\n",
            "Epoch 10: Loss: 0.6925950646400452\n",
            "Epoch 11: Loss: 0.6543896794319153\n",
            "Epoch 12: Loss: 0.6488059759140015\n",
            "Epoch 13: Loss: 0.6715931296348572\n",
            "Epoch 14: Loss: 0.650654137134552\n",
            "Epoch 15: Loss: 0.6456484198570251\n",
            "Epoch 16: Loss: 0.680456280708313\n",
            "Epoch 17: Loss: 0.644891619682312\n",
            "Epoch 18: Loss: 0.6450093388557434\n",
            "Epoch 19: Loss: 0.6580612659454346\n",
            "Epoch 20: Loss: 0.6571075916290283\n",
            "Epoch 21: Loss: 0.6886199712753296\n",
            "Epoch 22: Loss: 0.6921493411064148\n",
            "Epoch 23: Loss: 0.6513641476631165\n",
            "Epoch 24: Loss: 0.6274493932723999\n",
            "Epoch 25: Loss: 0.641273021697998\n",
            "Epoch 26: Loss: 0.6714808344841003\n",
            "Epoch 27: Loss: 0.6532477736473083\n",
            "Epoch 28: Loss: 0.6339865922927856\n",
            "Epoch 29: Loss: 0.6293105483055115\n",
            "Epoch 30: Loss: 0.6461070775985718\n",
            "Epoch 31: Loss: 0.7348917722702026\n",
            "Epoch 32: Loss: 0.6064228415489197\n",
            "Epoch 33: Loss: 0.6444141268730164\n",
            "Epoch 34: Loss: 0.6864667534828186\n",
            "Epoch 35: Loss: 0.6295071840286255\n",
            "Epoch 36: Loss: 0.7015998363494873\n",
            "Epoch 37: Loss: 0.6419760584831238\n",
            "Epoch 38: Loss: 0.6141161918640137\n",
            "Epoch 39: Loss: 0.6184139251708984\n",
            "Epoch 40: Loss: 0.6909961104393005\n",
            "Epoch 41: Loss: 0.6428728699684143\n",
            "Epoch 42: Loss: 0.6278176307678223\n",
            "Epoch 43: Loss: 0.7380877733230591\n",
            "Epoch 44: Loss: 0.6544403433799744\n",
            "Epoch 45: Loss: 0.6673420667648315\n",
            "Epoch 46: Loss: 0.6098583340644836\n",
            "Epoch 47: Loss: 0.592609167098999\n",
            "Epoch 48: Loss: 0.6134892106056213\n",
            "Epoch 49: Loss: 0.6183714270591736\n",
            "Epoch 50: Loss: 0.6656047701835632\n",
            "Epoch 51: Loss: 0.6203480958938599\n",
            "Epoch 52: Loss: 0.7321273684501648\n",
            "Epoch 53: Loss: 0.5802407264709473\n",
            "Epoch 54: Loss: 0.6453555822372437\n",
            "Epoch 55: Loss: 0.6944289207458496\n",
            "Epoch 56: Loss: 0.6098182201385498\n",
            "Epoch 57: Loss: 0.6432428956031799\n",
            "Epoch 58: Loss: 0.6640433669090271\n",
            "Epoch 59: Loss: 0.5905860066413879\n",
            "Epoch 60: Loss: 0.6829878687858582\n",
            "Epoch 61: Loss: 0.5878166556358337\n",
            "Epoch 62: Loss: 0.5890312790870667\n",
            "Epoch 63: Loss: 0.5311400890350342\n",
            "Epoch 64: Loss: 0.7105941772460938\n",
            "Epoch 65: Loss: 0.6771022081375122\n",
            "Epoch 66: Loss: 0.7712042927742004\n",
            "Epoch 67: Loss: 0.622582733631134\n",
            "Epoch 68: Loss: 0.6823025345802307\n",
            "Epoch 69: Loss: 0.5832551717758179\n",
            "Epoch 70: Loss: 0.6946070194244385\n",
            "Epoch 71: Loss: 0.6483069658279419\n",
            "Epoch 72: Loss: 0.7430076003074646\n",
            "Epoch 73: Loss: 0.6443918943405151\n",
            "Epoch 74: Loss: 0.6874065399169922\n",
            "Epoch 75: Loss: 0.6204424500465393\n",
            "Epoch 76: Loss: 0.6503936052322388\n",
            "Epoch 77: Loss: 0.554262638092041\n",
            "Epoch 78: Loss: 0.727895975112915\n",
            "Epoch 79: Loss: 0.6813488006591797\n",
            "Epoch 80: Loss: 0.6112266778945923\n",
            "Epoch 81: Loss: 0.7015517354011536\n",
            "Epoch 82: Loss: 0.7267798781394958\n",
            "Epoch 83: Loss: 0.7827126979827881\n",
            "Epoch 84: Loss: 0.5425497889518738\n",
            "Epoch 85: Loss: 0.7044510841369629\n",
            "Epoch 86: Loss: 0.5379740595817566\n",
            "Epoch 87: Loss: 0.5836097598075867\n",
            "Epoch 88: Loss: 0.44254687428474426\n",
            "Epoch 89: Loss: 0.6451191902160645\n",
            "Epoch 90: Loss: 0.756253719329834\n",
            "Epoch 91: Loss: 0.7327575087547302\n",
            "Epoch 92: Loss: 0.6850761771202087\n",
            "Epoch 93: Loss: 0.7341746687889099\n",
            "Epoch 94: Loss: 0.6267731785774231\n",
            "Epoch 95: Loss: 0.6508757472038269\n",
            "Epoch 96: Loss: 0.621824324131012\n",
            "Epoch 97: Loss: 0.5481142997741699\n",
            "Epoch 98: Loss: 0.49802449345588684\n",
            "Epoch 99: Loss: 0.6442506313323975\n",
            "\n",
            "Test set: Average loss: 0.5869, Accuracy: 114/156 (73%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}